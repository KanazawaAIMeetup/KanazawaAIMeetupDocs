# AnoGANについて

# GANによる異常検知の直感的な理解

この記事ではGANを用いた異常検知やAutoEncoderを用いた異常検知のを初心者でもわかる直感的な説明で紹介しようと思います。GANを用いた異常検知は、教師データが少ない場合に威力を発揮します。なので、完全に教師なし学習として使われるケースはあまり無いと思います。

ただし、一部の異常検知の手法は異常である/ないといったラベル（教師データ）は必要ありません。これは、教師なしの異常検知と呼ばれます。(AIにデータを渡すと、勝手に異常と思われるデータを除外してくれるイメージです。もちろん、閾値は決めなければならないですし、正しい保証もありません。)詳しくは、時間があれば書き足します。

# 異常検知って
異常検知というと、AutoEncoderを私はすぐに思い浮かべます。しかし、近年GANを用いた手法なども盛んに開発されています。2018年に聞いた話なのですが、製造業の企業でGANを用いて既に異常検知をしている企業もあるという話を伺いました。

## Auto Encoderによる異常検知

Auto Encoderは、エンコーダとデコーダを用いることにより、入力画像と同じ画像を出力させることを目的としたディープラーニングの手法です。

## AnoGAN

AnoGAN[^1][^2]は通常のDCGANで学習を行ったGenerator部分のネットワークを用いて、少し工夫を施すことで異常検知にも使えるようにするという手法です。

![](https://i.imgur.com/QwxwRGI.png)


アルゴリズムの流れを説明します。

1. まず、テストデータ（画像など）を用意する。
1. テストデータ(正常な画像と異常な画像両方含まれる）を参考にGeneratorの入力となる最適と思われる乱数zを生成し、その乱数を元にテストデータと似たような画像を出力できるようにする。(注意：GeneratorやDiscriminatorの学習は一切行いません)
1. 乱数zをGeneratorに入力して、画像を出力してみる。
1. 正常な画像（つまりDCGANを学習する段階で多く経験した似たような画像）はテスト画像に似たような画像を上手く出力できるのに対し、異常画像を元に乱数を生成し、それを元にGeneratorから画像を出力すると上手く出力できない。
1. 評価する。テスト画像と出力された画像の類似度を、画素ごとの引き算を行い絶対値をとったものなどで求める。正確には、それに加えて、テスト画像と、出力された画像それぞれを用いてDiscriminatorに通し、出力層の一個手前の層で出現した特徴量を引き算し、絶対値をとったものも類似度を測る指標として使う。

肝心のイメージですが、AutoEncoderを用いた異常検知と似ていると思います。今まで多く見てきた画像とテスト画像が似ていれば、少ない情報に変換して（zという乱数に変換して）再び復元しようとした場合、上手く復元できますが、今までAIが見てきた画像と大きく異なる画像の場合、一旦少ない情報に変換して(zという値に変換して)元のテスト画像を復元しようとしても上手くいきません。

上手く復元できたかどうか=今までAIが見てきた画像と似ている正常な画像かどうか　です。
似ているかどうかは、類似度を測って求めます。類似度の測り方については様々な手法があります。例えば、Cos類似度、KL情報量(ヒストグラムを書いて重なっている部分の面積が大きいか、小さいか)、単純に2枚の写真の同じ位置の画素同士を引き算する　などがあります。

## AnoGANの誤差関数

AnoGANでは、residual lossとdiscrimination lossの二つを割合を考えて足し合わせたものを誤差関数として用います。

テスト画像（判定したい画像）と乱数を元に生成された画像について、同じ位置の画素同士を引き算を行い絶対値をとったものの合計を、residual loss（累積的な誤差）と呼びます。

一方、discrimination lossはテスト画像と、テスト画像を元に生成された乱数を元に、復元された（生成された）画像両方をGANのdiscriminator部分に与え、出力層の一個手前の特徴量同士を引き算し、絶対値をとったものである。

![](https://i.imgur.com/56xml9L.png)


誤差関数の数式は以下のようになります。

```math
loss = (1-λ) × residual loss + λ × discrimination loss
```

やっていることは単純。AnoGANの論文ではλに0.1が採用された。つまり、residual lossに9割、discrimination lossは1割の重み付けを行う。residual lossの方が大事だと考えている。

## ハンズオン（力尽きた...）

「つくりながら学ぶ! PyTorchによる発展ディープラーニング[^3]」という本のサンプルコード[^4]がgithubで手に入ります。詳しくはこちらを参照してください。


## 教師なしの異常検知
教師ありの異常検知は皆さんどのように実装すれば良いか簡単に想像がつくと思いますが、教師なしの異常検知はパッと考えただけでは思いつかないと思います。

教師なしの異常検知の動作の仕組みを述べると、

- データの中から、外れ値のようなもの（例えば他の写真と大きく異なる）を探す
- 閾値を決めて大きく外れていると思われるデータは除外する

といった感じになります。詳しくは時間があれば追記します。

## 引用元、参考文献のリスト
[^1]: Thomas Schlegl, Philipp Seeböck, Sebastian M. Waldstein, Ursula Schmidt-Erfurth, Georg Langs. Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery (https://arxiv.org/abs/1703.05921)


[^2]: AnoGAN (https://link.springer.com/chapter/10.1007/978-3-319-59050-9_12)


[^3]: つくりながら学ぶ！PyTorchによる発展ディープラーニン(https://book.mynavi.jp/ec/products/detail/id=104855)


[^4]: YutaroOgawa/pytorch_advanced: 書籍「つくりながら学ぶ! PyTorchによる発展ディープラーニング」の実装コードを配置したリポジトリです(https://github.com/YutaroOgawa/pytorch_advanced/blob/master/6_gan_anomaly_detection/6-2_AnoGAN.ipynb)

